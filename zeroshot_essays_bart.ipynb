{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from transformers import BartForSequenceClassification, BartTokenizer, Trainer, TrainingArguments, BartConfig\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the configuration of the pre-trained model\n",
    "config = BartConfig.from_pretrained('facebook/bart-large-mnli')\n",
    "config.num_labels = 9\n",
    "\n",
    "# Load data\n",
    "def __getitem__(self, idx):\n",
    "    item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    try:\n",
    "        item['labels'] = torch.tensor(labels.index(self.labels[idx]))\n",
    "    except ValueError:\n",
    "        print(f\"Warning: Label {self.labels[idx]} not found in labels list!\")\n",
    "        item['labels'] = torch.tensor(-1)  # or some default value\n",
    "    return item\n",
    "\n",
    "df = pd.read_csv('/Users/aryan/Actual-Coding/CDAC/feedback-prize-english-language-learning/train.csv')\n",
    "data = df[1:6]\n",
    "labels = [\"1.0\", \"1.5\", \"2.0\", \"2.5\", \"3.0\", \"3.5\", \"4.0\", \"4.5\", \"5.0\"]\n",
    "\n",
    "# Prepare data for each metric\n",
    "def prepare_data_for_metric(metric):\n",
    "    texts = data['full_text'].tolist()\n",
    "    metric_scores = data[metric].astype(str).tolist()\n",
    "    return texts, metric_scores\n",
    "\n",
    "# Training function\n",
    "def train_model_for_metric(metric):\n",
    "    # Load tokenizer and model\n",
    "    tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "    model = BartForSequenceClassification(config)\n",
    "    \n",
    "    # Prepare data\n",
    "    texts, metric_scores = prepare_data_for_metric(metric)\n",
    "    \n",
    "    # Tokenize data\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(texts, metric_scores, test_size=0.1)\n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # Create a Torch Dataset\n",
    "    class EssayDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            item['labels'] = torch.tensor(labels.index(self.labels[idx]))\n",
    "            return item\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "    train_dataset = EssayDataset(train_encodings, train_labels)\n",
    "    val_dataset = EssayDataset(val_encodings, val_labels)\n",
    "    \n",
    "    # Define training arguments and initialize Trainer\n",
    "    training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=8,\n",
    "        num_train_epochs=3,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        do_train=True,\n",
    "        no_cuda=False,\n",
    "        load_best_model_at_end=True,\n",
    "        save_strategy=\"epoch\",\n",
    "        report_to=\"tensorboard\", # type: ignore\n",
    "        output_dir=f'./essay-output/results_{metric}'\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the model\n",
    "    model.save_pretrained(f'./essay-output/bart_{metric}')\n",
    "    tokenizer.save_pretrained(f'./essay-output/bart_{metric}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train a model for each metric\n",
    "metrics = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "models = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070b2f6d220a444e8dc742e7e441fbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7104f093f47a4c9c96c1475dcf4baf7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7970407009124756, 'eval_runtime': 0.3362, 'eval_samples_per_second': 2.974, 'eval_steps_per_second': 2.974, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475f2a3c80dc4c27adce24abb13fc3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0328681468963623, 'eval_runtime': 0.7073, 'eval_samples_per_second': 1.414, 'eval_steps_per_second': 1.414, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb4e57abefd494180bad3ededd8be0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.000910997390747, 'eval_runtime': 0.6986, 'eval_samples_per_second': 1.431, 'eval_steps_per_second': 1.431, 'epoch': 3.0}\n",
      "{'train_runtime': 284.818, 'train_samples_per_second': 0.042, 'train_steps_per_second': 0.011, 'train_loss': 1.6387874285380046, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "models['cohesion'] = train_model_for_metric('cohesion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d379d7c4a74c4080fdcf49f109659e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330eb839d5964d1ca03bb6d586efeb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.576262474060059, 'eval_runtime': 2.4512, 'eval_samples_per_second': 0.408, 'eval_steps_per_second': 0.408, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ac1857518544b293a69f6ed87629bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.794909477233887, 'eval_runtime': 3.6476, 'eval_samples_per_second': 0.274, 'eval_steps_per_second': 0.274, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7f9b92a9ed4c2095a9cd2447b79586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.635828971862793, 'eval_runtime': 4.0797, 'eval_samples_per_second': 0.245, 'eval_steps_per_second': 0.245, 'epoch': 3.0}\n",
      "{'train_runtime': 400.8259, 'train_samples_per_second': 0.03, 'train_steps_per_second': 0.007, 'train_loss': 1.4741125106811523, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "models['syntax'] = train_model_for_metric('syntax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7cdbdf66c14daea471285a99ec5dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bc6fc721984bd6a899cbf729090c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4671934247016907, 'eval_runtime': 3.4712, 'eval_samples_per_second': 0.288, 'eval_steps_per_second': 0.288, 'epoch': 1.0}\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is free. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 264.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aryan\\Actual-Coding\\CDAC\\zeroshot_essays_bart.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m models[\u001b[39m'\u001b[39m\u001b[39mvocabulary\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m train_model_for_metric(\u001b[39m'\u001b[39;49m\u001b[39mvocabulary\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\aryan\\Actual-Coding\\CDAC\\zeroshot_essays_bart.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X26sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X26sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X26sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X26sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     train_dataset\u001b[39m=\u001b[39mtrain_dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X26sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     eval_dataset\u001b[39m=\u001b[39mval_dataset,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X26sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X26sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X26sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X26sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39m# Save the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X26sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m model\u001b[39m.\u001b[39msave_pretrained(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./essay-output/bart_\u001b[39m\u001b[39m{\u001b[39;00mmetric\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1536\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1537\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1538\u001b[0m )\n\u001b[1;32m-> 1539\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1540\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1541\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1542\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1543\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1544\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:1809\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1806\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m   1808\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1809\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1811\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1812\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1813\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1814\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1815\u001b[0m ):\n\u001b[0;32m   1816\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1817\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:2654\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2651\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   2653\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2654\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[0;32m   2656\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2657\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2678\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2679\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[0;32m   2680\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2681\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2682\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1530\u001b[0m, in \u001b[0;36mBartForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[39mif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1526\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   1527\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing input embeddings is currently not supported for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1528\u001b[0m     )\n\u001b[1;32m-> 1530\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[0;32m   1531\u001b[0m     input_ids,\n\u001b[0;32m   1532\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1533\u001b[0m     decoder_input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[0;32m   1534\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[0;32m   1535\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1536\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[0;32m   1537\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[0;32m   1538\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[0;32m   1539\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1540\u001b[0m     decoder_inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[0;32m   1541\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1542\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1543\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1544\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1545\u001b[0m )\n\u001b[0;32m   1546\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]  \u001b[39m# last hidden state\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m eos_mask \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39meq(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39meos_token_id)\u001b[39m.\u001b[39mto(hidden_states\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1266\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[0;32m   1260\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[0;32m   1261\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1262\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1263\u001b[0m     )\n\u001b[0;32m   1265\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1266\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[0;32m   1267\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[0;32m   1268\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[0;32m   1269\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_outputs[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m   1270\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1271\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[0;32m   1272\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[0;32m   1273\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1274\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[0;32m   1275\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1276\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1277\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1278\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1279\u001b[0m )\n\u001b[0;32m   1281\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n\u001b[0;32m   1282\u001b[0m     \u001b[39mreturn\u001b[39;00m decoder_outputs \u001b[39m+\u001b[39m encoder_outputs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1124\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m   1114\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[0;32m   1115\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1122\u001b[0m     )\n\u001b[0;32m   1123\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1124\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[0;32m   1125\u001b[0m         hidden_states,\n\u001b[0;32m   1126\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1127\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1128\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m   1129\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49m(head_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1130\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49m(\n\u001b[0;32m   1131\u001b[0m             cross_attn_head_mask[idx] \u001b[39mif\u001b[39;49;00m cross_attn_head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m   1132\u001b[0m         ),\n\u001b[0;32m   1133\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[0;32m   1134\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1135\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1136\u001b[0m     )\n\u001b[0;32m   1137\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1139\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:427\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[0;32m    425\u001b[0m self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[39m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[39;00m\n\u001b[1;32m--> 427\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[0;32m    428\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[0;32m    429\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    430\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    431\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m    432\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    433\u001b[0m )\n\u001b[0;32m    434\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[0;32m    435\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1502\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1509\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1510\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1512\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:219\u001b[0m, in \u001b[0;36mBartAttention.forward\u001b[1;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    217\u001b[0m     \u001b[39m# self_attention\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     key_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_proj(hidden_states), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, bsz)\n\u001b[1;32m--> 219\u001b[0m     value_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shape(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj(hidden_states), \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, bsz)\n\u001b[0;32m    221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_decoder:\n\u001b[0;32m    222\u001b[0m     \u001b[39m# if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[39m# Further calls to cross_attention layer can then reuse all cross-attention\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[39m# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[39m# if encoder bi-directional self-attention `past_key_value` is always `None`\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     past_key_value \u001b[39m=\u001b[39m (key_states, value_states)\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:173\u001b[0m, in \u001b[0;36mBartAttention._shape\u001b[1;34m(self, tensor, seq_len, bsz)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_shape\u001b[39m(\u001b[39mself\u001b[39m, tensor: torch\u001b[39m.\u001b[39mTensor, seq_len: \u001b[39mint\u001b[39m, bsz: \u001b[39mint\u001b[39m):\n\u001b[1;32m--> 173\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49mview(bsz, seq_len, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhead_dim)\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39;49mcontiguous()\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 6.00 GiB of which 0 bytes is free. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 264.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "models['vocabulary'] = train_model_for_metric('vocabulary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['phraseology'] = train_model_for_metric('phraseology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['grammar'] = train_model_for_metric('grammar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['conventions'] = train_model_for_metric('conventions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a test for a course about Huggingface transformer libraries',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.9200394749641418, 0.06149790808558464, 0.018462616950273514]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\", \n",
    "    model=\"facebook/bart-large-mnli\")\n",
    "classifier(\n",
    "    \"This is a test for a course about Huggingface transformer libraries\",\n",
    "    candidate_labels = [\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "essays_train = pd.DataFrame(pd.read_csv('/Users/aryan/Actual-Coding/CDAC/feedback-prize-english-language-learning/train.csv'))\n",
    "essays = essays_train['full_text']\n",
    "essays_for_testing = essays[1:6]\n",
    "labels = 'cohesion','syntax','vocabulary','phraseology','grammar','conventions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cohesion\n",
       "3.0         1096\n",
       "3.5          988\n",
       "2.5          790\n",
       "4.0          534\n",
       "2.0          315\n",
       "4.5          125\n",
       "1.5           27\n",
       "5.0           26\n",
       "1.0           10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohesion_list = pd.DataFrame(essays_train['cohesion'])\n",
    "cohesion_list.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohesion  syntax  vocabulary  phraseology  grammar  conventions\n",
       "1       2.5     2.5         3.0          2.0      2.0          2.5\n",
       "2       3.0     3.5         3.0          3.0      3.0          2.5\n",
       "3       4.5     4.5         4.5          4.5      4.0          5.0\n",
       "4       2.5     3.0         3.0          3.0      2.5          2.5\n",
       "5       3.5     4.0         4.0          3.5      3.5          4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_score_real = pd.DataFrame(essays_train.iloc[1:6 , 2:8])\n",
    "essays_score_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    When a problem is a change you have to let it ...\n",
       "2    Dear, Principal\\n\\nIf u change the school poli...\n",
       "3    The best time in life is when you become yours...\n",
       "4    Small act of kindness can impact in other peop...\n",
       "5    Dear Principal,\\r\\n\\r\\nOur school should have ...\n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_for_testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sequence       labels  scores\n",
      "0  I think that students would benefit from learn...     cohesion     4.0\n",
      "1  I think that students would benefit from learn...  conventions     3.5\n",
      "2  I think that students would benefit from learn...  phraseology     3.5\n",
      "3  I think that students would benefit from learn...   vocabulary     3.5\n",
      "4  I think that students would benefit from learn...      grammar     3.5\n",
      "5  I think that students would benefit from learn...       syntax     3.5\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\", \n",
    "    model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "result1 = []\n",
    "result1 = classifier(\n",
    "    \"I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. Taking only classes helps them because at there house they'll be pay more attention. they will be comfortable at home. The hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and you'll either not like it or you look and see a stain. Then you'll have to change. With the online classes you can wear anything and stay home and you wont need to stress about what to wear. Most students usually take showers before school. they either take it before they sleep or when they wake up. some students do both to smell good. that causes them do miss the bus and effects on there lesson time cause they come late to school. When u have online classes u wont need to miss lessons cause you can get everything set up and go take a shower and when u get out your ready to go. When your home your comfortable and you pay attention. It gives then an advantage to be smarter and even pass there classmates on class work. Public schools are difficult even if you try. some teacher dont know how to teach it in then way that students understand it. That causes students to fail and they may repeat the class.              \",\n",
    "    candidate_labels = labels,\n",
    ")\n",
    "\n",
    "output1 = pd.DataFrame(result1) # type: ignore\n",
    "output1['scores'] = round(((output1['scores'] * 3.0) + 3.0) * 10.0)\n",
    "output1['scores'] = output1['scores'] / 10.0\n",
    "output1['scores'] = round(output1['scores'] * 2) / 2 # type: ignore\n",
    "\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\", \n",
    "    model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "result_set = []\n",
    "for essay in essays_for_testing:\n",
    "    result = classifier(\n",
    "        essay,\n",
    "        candidate_labels = labels,\n",
    "    )\n",
    "    result_set.append(result['scores']) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "output = pd.DataFrame(result_set, columns = labels)\n",
    "output = round(((output * 3.0) + 3.0) * 10.0)\n",
    "output = output / 10.0 # type: ignore\n",
    "output = round(output * 2) / 2 # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"essays_output.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohesion  syntax  vocabulary  phraseology  grammar  conventions\n",
       "0       4.0     3.5         3.5          3.5      3.5          3.5\n",
       "1       4.5     3.5         3.5          3.5      3.0          3.0\n",
       "2       3.5     3.5         3.5          3.5      3.5          3.5\n",
       "3       4.0     3.5         3.5          3.5      3.0          3.0\n",
       "4       4.0     3.5         3.5          3.5      3.5          3.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_score_pred = pd.DataFrame(pd.read_csv('/Users/aryan/Actual-Coding/CDAC/essays_output.csv'))\n",
    "essays_score_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cohesion       int32\n",
       "syntax         int32\n",
       "vocabulary     int32\n",
       "phraseology    int32\n",
       "grammar        int32\n",
       "conventions    int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_score_real.astype('int').dtypes\n",
    "essays_score_pred.astype('int').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared:\n",
      " -0.30803724577309494\n",
      "\n",
      "Mean Absolute Error:\n",
      " 0.7333333333333333\n",
      "\n",
      "Mean Squared Error:\n",
      " 0.7666666666666666\n",
      "\n",
      "Root Mean Squared Error:\n",
      " 0.8755950357709131\n",
      "\n",
      "Median Absolute Error:\n",
      " 0.6666666666666666\n",
      "\n",
      "Mean Absolute Percentage Error:\n",
      " cohesion       41.944444\n",
      "syntax         19.722222\n",
      "vocabulary     18.055556\n",
      "phraseology    32.638889\n",
      "grammar        32.916667\n",
      "conventions    35.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r_squared = r2_score(essays_score_real, essays_score_pred)\n",
    "print(\"R-squared:\\n\", r_squared)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(essays_score_real, essays_score_pred)\n",
    "print(\"\\nMean Absolute Error:\\n\", mae)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(essays_score_real, essays_score_pred)\n",
    "print(\"\\nMean Squared Error:\\n\", mse)\n",
    "\n",
    "import numpy as np\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"\\nRoot Mean Squared Error:\\n\", rmse)\n",
    "\n",
    "from sklearn.metrics import median_absolute_error\n",
    "medae = median_absolute_error(essays_score_real, essays_score_pred)\n",
    "print(\"\\nMedian Absolute Error:\\n\", medae)\n",
    "\n",
    "import numpy as np\n",
    "mape = np.mean(np.abs((essays_score_real - essays_score_pred) / essays_score_real)) * 100\n",
    "print(\"\\nMean Absolute Percentage Error:\\n\", mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_11816\\4001257315.py:11: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(essays_train[col], fit=stats.norm)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_11816\\4001257315.py:11: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(essays_train[col], fit=stats.norm)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_11816\\4001257315.py:11: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(essays_train[col], fit=stats.norm)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_11816\\4001257315.py:11: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(essays_train[col], fit=stats.norm)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_11816\\4001257315.py:11: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(essays_train[col], fit=stats.norm)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_11816\\4001257315.py:11: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(essays_train[col], fit=stats.norm)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2200x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "figure = plt.figure(figsize = (22,5))\n",
    "for i, col in enumerate(essays_train.select_dtypes(['int32','float']).columns): \n",
    "    ax = plt.subplot(1, 26, i+1)\n",
    "    if essays_train[col].dtype == 'int32': \n",
    "        sns.distplot(essays_train[col], fit=stats.norm, color = 'red')        \n",
    "    else: \n",
    "        sns.distplot(essays_train[col], fit=stats.norm)        \n",
    "    ax.set_ylim((0.0, 5.0))\n",
    "figure.tight_layout(h_pad=1.0, w_pad=0.5)\n",
    "plt.suptitle('Distribution Plots', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_11816\\334860329.py:11: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(essays_score_pred[col], fit=stats.norm)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_11816\\334860329.py:11: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(essays_score_pred[col], fit=stats.norm)\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\distributions.py:2511: UserWarning: Dataset has 0 variance; skipping density estimate. Pass `warn_singular=False` to disable this warning.\n",
      "  kdeplot(**{axis: a}, ax=ax, color=kde_color, **kde_kws)\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2093: RuntimeWarning: invalid value encountered in divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_11816\\334860329.py:11: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(essays_score_pred[col], fit=stats.norm)\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\distributions.py:2511: UserWarning: Dataset has 0 variance; skipping density estimate. Pass `warn_singular=False` to disable this warning.\n",
      "  kdeplot(**{axis: a}, ax=ax, color=kde_color, **kde_kws)\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2093: RuntimeWarning: invalid value encountered in divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_11816\\334860329.py:11: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(essays_score_pred[col], fit=stats.norm)\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\distributions.py:2511: UserWarning: Dataset has 0 variance; skipping density estimate. Pass `warn_singular=False` to disable this warning.\n",
      "  kdeplot(**{axis: a}, ax=ax, color=kde_color, **kde_kws)\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2093: RuntimeWarning: invalid value encountered in divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_11816\\334860329.py:11: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(essays_score_pred[col], fit=stats.norm)\n",
      "C:\\Users\\aryan\\AppData\\Local\\Temp\\ipykernel_11816\\334860329.py:11: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(essays_score_pred[col], fit=stats.norm)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2200x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "figure = plt.figure(figsize = (22,5))\n",
    "for i, col in enumerate(essays_score_pred.select_dtypes(['int32','float']).columns): \n",
    "    ax = plt.subplot(1, 26, i+1)\n",
    "    if essays_score_pred[col].dtype == 'int32': \n",
    "        sns.distplot(essays_score_pred[col], fit=stats.norm, color = 'blue')        \n",
    "    else: \n",
    "        sns.distplot(essays_score_pred[col], fit=stats.norm)        \n",
    "    ax.set_ylim((0.0, 5.0))\n",
    "figure.tight_layout(h_pad=1.0, w_pad=0.5)\n",
    "plt.suptitle('Distribution Plots', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "\n",
    "# Prepare and tokenize dataset\n",
    "essays_train = pd.DataFrame(pd.read_csv('/Users/aryan/Actual-Coding/CDAC/feedback-prize-english-language-learning/train.csv'))\n",
    "essays = essays_train['full_text']\n",
    "x_train = essays[1:10]\n",
    "cohesions = essays_train['cohesion']\n",
    "y_train = cohesions[1:10]\n",
    "\n",
    "essays_test = pd.DataFrame(pd.read_csv('/Users/aryan/Actual-Coding/CDAC/feedback-prize-english-language-learning/train.csv'))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples, padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function)\n",
    "\n",
    "train_dataset, eval_dataset = \n",
    "\n",
    "# Setup evaluation \n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Load pretrained model and evaluate model after each epoch\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=6)\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large-mnli and are newly initialized because the shapes did not match:\n",
      "- classification_head.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "- classification_head.out_proj.weight: found shape torch.Size([3, 1024]) in the checkpoint and torch.Size([6, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdab685ddf694f8aaa07ac7f7bb689cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "vars() argument must have __dict__ attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aryan\\Actual-Coding\\CDAC\\zeroshot_essays_bart.ipynb Cell 15\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X21sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# Training loop with custom optimizer\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X21sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(training_args\u001b[39m.\u001b[39mnum_train_epochs): \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X21sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aryan/Actual-Coding/CDAC/zeroshot_essays_bart.ipynb#X21sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     trainer\u001b[39m.\u001b[39mevaluate()\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1536\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1537\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1538\u001b[0m )\n\u001b[1;32m-> 1539\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1540\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1541\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1542\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1543\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1544\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer.py:1787\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1784\u001b[0m     rng_to_sync \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m-> 1787\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epoch_iterator):\n\u001b[0;32m   1788\u001b[0m     total_batched_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1789\u001b[0m     \u001b[39mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\accelerate\\data_loader.py:384\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 384\u001b[0m     current_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(dataloader_iter)\n\u001b[0;32m    385\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[39myield\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\trainer_utils.py:704\u001b[0m, in \u001b[0;36mRemoveColumnsCollator.__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, features: List[\u001b[39mdict\u001b[39m]):\n\u001b[0;32m    703\u001b[0m     features \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remove_columns(feature) \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m features]\n\u001b[1;32m--> 704\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_collator(features)\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\data\\data_collator.py:70\u001b[0m, in \u001b[0;36mdefault_data_collator\u001b[1;34m(features, return_tensors)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39m# In this function we'll make the assumption that all `features` in the batch\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[39m# have the same attributes.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[39m# So we will look at the first element as a proxy for what attributes exist\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39m# on the whole batch.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m return_tensors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mreturn\u001b[39;00m torch_default_data_collator(features)\n\u001b[0;32m     71\u001b[0m \u001b[39melif\u001b[39;00m return_tensors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m tf_default_data_collator(features)\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\data\\data_collator.py:109\u001b[0m, in \u001b[0;36mtorch_default_data_collator\u001b[1;34m(features)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(features[\u001b[39m0\u001b[39m], Mapping):\n\u001b[1;32m--> 109\u001b[0m     features \u001b[39m=\u001b[39m [\u001b[39mvars\u001b[39m(f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m features]\n\u001b[0;32m    110\u001b[0m first \u001b[39m=\u001b[39m features[\u001b[39m0\u001b[39m]\n\u001b[0;32m    111\u001b[0m batch \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\aryan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\data\\data_collator.py:109\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(features[\u001b[39m0\u001b[39m], Mapping):\n\u001b[1;32m--> 109\u001b[0m     features \u001b[39m=\u001b[39m [\u001b[39mvars\u001b[39;49m(f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m features]\n\u001b[0;32m    110\u001b[0m first \u001b[39m=\u001b[39m features[\u001b[39m0\u001b[39m]\n\u001b[0;32m    111\u001b[0m batch \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;31mTypeError\u001b[0m: vars() argument must have __dict__ attribute"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, AdamW\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=training_args.learning_rate)\n",
    "\n",
    "# Prepare and tokenize dataset\n",
    "essays = pd.DataFrame(pd.read_csv('/Users/aryan/Actual-Coding/CDAC/feedback-prize-english-language-learning/train.csv'))\n",
    "#essays_train = pd.DataFrame(pd.read_csv('/Users/aryan/Actual-Coding/CDAC/feedback-prize-english-language-learning/train.csv'))\n",
    "#essays = essays_train['full_text']\n",
    "dataset = essays[1:20]\n",
    "\n",
    "# Split the dataset into train and test\n",
    "train_texts, test_texts = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples, padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Tokenize the datasets\n",
    "labels_train = train_texts['full_test'].tolist()  # Replace 'label_column_name' with the actual column name of the labels\n",
    "labels_test = test_texts['full_text'].tolist()\n",
    "\n",
    "tokenized_train = tokenize_function(train_texts['full_text'].tolist())\n",
    "tokenized_test = tokenize_function(test_texts['full_text'].tolist())\n",
    "\n",
    "train_dataset = [{'input_ids': input_id, 'attention_mask': attention_mask, 'labels': label} for input_id, attention_mask, label in zip(tokenized_train[\"input_ids\"], tokenized_train[\"attention_mask\"], labels_train)]\n",
    "test_dataset = [{'input_ids': input_id, 'attention_mask': attention_mask, 'labels': label} for input_id, attention_mask, label in zip(tokenized_test[\"input_ids\"], tokenized_test[\"attention_mask\"], labels_test)]\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = tokenized_train[\"input_ids\"], tokenized_train[\"attention_mask\"]\n",
    "test_dataset = tokenized_test[\"input_ids\"], tokenized_test[\"attention_mask\"]\n",
    "\n",
    "# Setup evaluation \n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)\n",
    "\n",
    "# Load pretrained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\", num_labels=6, ignore_mismatched_sizes=True)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./test_trainer\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=8,  # Adjust batch size as needed\n",
    "    per_device_eval_batch_size=8,   # Adjust batch size as needed\n",
    "    logging_dir=\"./logs\",\n",
    "    save_steps=10,\n",
    "    save_total_limit=5,\n",
    "    num_train_epochs=3,\n",
    "    overwrite_output_dir=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset, # type: ignore\n",
    "    eval_dataset=test_dataset, # type: ignore\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Define your custom optimizer (e.g., torch.optim.AdamW)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=training_args.learning_rate)\n",
    "\n",
    "# Training loop with custom optimizer\n",
    "for epoch in range(training_args.num_train_epochs): # type: ignore\n",
    "    trainer.train()\n",
    "    trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load your custom dataset along with label weights.\n",
    "essays_train = pd.read_csv('/Users/aryan/Actual-Coding/CDAC/feedback-prize-english-language-learning/train.csv')\n",
    "essays_test = pd.read_csv('/Users/aryan/Actual-Coding/CDAC/feedback-prize-english-language-learning/test.csv')\n",
    "\n",
    "# Tokenize the text data.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "encoded_inputs = tokenizer(\n",
    "    pd.Series(essays_train['full_text']).tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",  # Return PyTorch tensors\n",
    "    max_length=32,  # Set your desired maximum sequence length\n",
    ")\n",
    "\n",
    "# Create PyTorch datasets and data loaders.\n",
    "train_input_ids = tf.constant(encoded_inputs[\"input_ids\"])\n",
    "train_attention_masks = tf.constant(encoded_inputs[\"attention_mask\"])\n",
    "train_labels = tf.constant(['cohesion','syntax','vocabulary','phraseology','grammar','conventions'])\n",
    "label_weights = tf.constant(essays_train['cohesion'], essays_train['syntax'], essays_train['vocabulary'], essays_train['phraseology'], essays_train['grammar'], essays_train['conventions']) # type: ignore\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels, label_weights)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Load and configure the model.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "model.config.num_labels = 4  # Set the number of labels for your task.\n",
    "\n",
    "# Define a custom loss function.\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=label_weights)\n",
    "\n",
    "# Training loop.\n",
    "for epoch in range(10):\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels, weights = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        # Backpropagation and model weight updates here.\n",
    "\n",
    "# Validation and testing code here.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
